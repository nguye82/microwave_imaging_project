{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReadData import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn import svm\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path, getTargetName = False):\n",
    "    # print(getTargetName)\n",
    "    data = getEMData(path)\n",
    "    target = []\n",
    "    field = []\n",
    "    freq = []\n",
    "    if getTargetName:\n",
    "        targetName = []\n",
    "        upper_case = [char for char in path if char.isupper()]\n",
    "        target_name = path[path.index(upper_case[0]):path.index(upper_case[1])]\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        target.append(data[i].target)\n",
    "        field.append(data[i].Esct.real)\n",
    "        freq.append(data[i].freq)\n",
    "        if getTargetName: targetName.append(target_name)\n",
    "\n",
    "    field = np.array(field)\n",
    "    target = np.array(target)\n",
    "    freq = np.array(freq)\n",
    "    if getTargetName: targetName = np.array(targetName)\n",
    "\n",
    "    result = (field, target, freq)\n",
    "    if getTargetName: result = (field, target, freq, targetName)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1470 samples\n"
     ]
    }
   ],
   "source": [
    "fieldCirc, targetCirc, freqCirc, shapeCirc = readData(path = \"./CircleData/\", getTargetName=True)\n",
    "\n",
    "fieldCirc = fieldCirc[np.where(freqCirc == 1e9)]\n",
    "targetCirc = targetCirc[np.where(freqCirc == 1e9)]\n",
    "freqCirc = freqCirc[np.where(freqCirc == 1e9)]\n",
    "\n",
    "fieldCirc_transformed = np.reshape(fieldCirc, (fieldCirc.shape[0], fieldCirc.shape[1], fieldCirc.shape[2], 1))\n",
    "targetCirc_transformed = np.reshape(targetCirc, (targetCirc.shape[0], targetCirc.shape[1], targetCirc.shape[2], 1))\n",
    "\n",
    "field_train, field_test, target_train, target_test, freq_train, freq_test= train_test_split(\n",
    "    fieldCirc_transformed, targetCirc_transformed, freqCirc, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(872, 24, 24, 1), (872, 50, 50, 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[field_train.shape, target_train.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 520 samples\n"
     ]
    }
   ],
   "source": [
    "fieldMNIST, targetMNIST, freqMNIST = readData(path = \"./MNIST_UNET/\", getTargetName=False)\n",
    "\n",
    "fieldMNIST_transformed = np.reshape(fieldMNIST, (fieldMNIST.shape[0], fieldMNIST.shape[1], fieldMNIST.shape[2], 1))\n",
    "targetMNIST_transformed = np.reshape(targetMNIST, (targetMNIST.shape[0], targetMNIST.shape[1], targetMNIST.shape[2], 1))\n",
    "\n",
    "fieldMNIST_train, fieldMNIST_test, targetMNIST_train, targetMNIST_test= train_test_split(\n",
    "    fieldMNIST_transformed, targetMNIST_transformed, test_size=0.20, random_state=42)\n",
    "\n",
    "fieldMNIST_train, fieldMNIST_val, targetMNIST_train, targetMNIST_val= train_test_split(\n",
    "    fieldMNIST_train, targetMNIST_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(332, 24, 24, 1), (332, 35, 35, 1), (84, 24, 24, 1), (84, 35, 35, 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fieldMNIST_train.shape,targetMNIST_train.shape, fieldMNIST_val.shape, targetMNIST_val.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, Activation, Input, Concatenate, AveragePooling2D,Add, Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    conv1 = Conv2D(64, 3, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(64, 3, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(64, 3, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(128, 3, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottleneck\n",
    "    bottleneck = Conv2D(256, 3, padding='same')(pool2)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "    bottleneck = Conv2D(256, 3, padding='same')(bottleneck)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = Activation('relu')(bottleneck)\n",
    "\n",
    "    # Expansive Path\n",
    "    up1 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(bottleneck)\n",
    "    skip1 = Concatenate(axis=-1)([conv2, up1])\n",
    "    conv3 = Conv2D(128, 3, padding='same')(skip1)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(128, 3, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "\n",
    "    up2 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(conv3)\n",
    "    skip2 = Concatenate(axis=-1)([conv1, up2])\n",
    "    conv4 = Conv2D(64, 3, padding='same')(skip2)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(64, 3, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "\n",
    "    up3 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(conv4)\n",
    "    # skip2 = Concatenate(axis=-1)([conv1, up2])\n",
    "    conv5 = Conv2D(32, 3, padding='same')(up3)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(32, 3, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    # Up-sample to (35, 35, 1)\n",
    "    # conv5 = Conv2DTranspose(1, (3, 3), strides=(2, 2), padding='same')(conv4)\n",
    "\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    # Cropping to the desired size (35, 35)\n",
    "    cropped_output = Cropping2D(((7, 6), (7, 6)))(output)\n",
    "    # skip3 = Concatenate(axis=-1)([input, cropped_output])\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=cropped_output)\n",
    "\n",
    "    # skip3 = Add()([inputs, conv5])\n",
    "\n",
    "    #     # Average pooling\n",
    "    # output = AveragePooling2D(pool_size=(1, 1))(skip3)\n",
    "\n",
    "    # model = Model(inputs=inputs, outputs=conv5)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 24, 24, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 24, 24, 64)   640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 24, 24, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 24, 24, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 24, 24, 64)   36928       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 24, 24, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 24, 24, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 24, 24, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 24, 24, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 24, 24, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 12, 12, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 12, 12, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 12, 12, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 12, 12, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 12, 12, 128)  147584      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 12, 12, 128)  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 12, 12, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 128)   0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 6, 6, 256)    295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 6, 6, 256)   1024        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 6, 6, 256)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 6, 6, 256)    590080      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 6, 6, 256)   1024        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 6, 6, 256)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 12, 12, 128)  295040     ['activation_6[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 12, 12, 256)  0           ['activation_4[0][0]',           \n",
      "                                                                  'conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 12, 12, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 12, 12, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 12, 12, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 12, 12, 128)  147584      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 12, 12, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 12, 12, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 24, 24, 64)  73792       ['activation_8[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 24, 24, 128)  0           ['activation_2[0][0]',           \n",
      "                                                                  'conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 24, 24, 64)   73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 24, 24, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 24, 24, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 24, 24, 64)   36928       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 24, 24, 64)  256         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 48, 48, 32)  18464       ['activation_10[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 48, 48, 32)   9248        ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 48, 48, 32)  128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 48, 48, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 48, 48, 32)   9248        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 48, 48, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 48, 48, 32)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 48, 48, 1)    33          ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 35, 35, 1)    0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,145,985\n",
      "Trainable params: 2,143,169\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputMNIST_shape = fieldMNIST_train.shape[1:]\n",
    "model_unet = unet(inputMNIST_shape)\n",
    "model_unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "# from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with suggested SGD, and logarithmic decay for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 1e-3\n",
    "final_lr = 1e-8\n",
    "total_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def log_learning_rate(num_epoch):\n",
    "    return np.logspace(np.log10(init_lr), np.log10(final_lr), num=num_epoch, endpoint=True)\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return log_learning_rate(total_epoch)[epoch]\n",
    "\n",
    "earlyStop = EarlyStopping(monitor='loss',patience=3)\n",
    "\n",
    "# def SGD_opt(model):\n",
    "#     lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "#     optimizer = tf.keras.optimizers.SGD(learning_rate=init_lr, momentum=0.99)\n",
    "#     model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = 'accuracy')\n",
    "#     return model.fit(x = fieldMNIST_train, y = targetMNIST_train, batch_size = 1, epochs = total_epoch, \n",
    "#                      callbacks = [lr_callback, EarlyStopping(monitor='loss',patience=3)])#stop when seeing no loss change in 3 consecutive epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17/17 [==============================] - 7s 357ms/step - loss: 0.0362 - accuracy: 0.9428 - val_loss: 0.1025 - val_accuracy: 0.9574\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 6s 332ms/step - loss: 0.0319 - accuracy: 0.9457 - val_loss: 0.0902 - val_accuracy: 0.9531\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 6s 368ms/step - loss: 0.0300 - accuracy: 0.9469 - val_loss: 0.0794 - val_accuracy: 0.9533\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 8s 456ms/step - loss: 0.0294 - accuracy: 0.9475 - val_loss: 0.0673 - val_accuracy: 0.9505\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 9s 543ms/step - loss: 0.0297 - accuracy: 0.9471 - val_loss: 0.0704 - val_accuracy: 0.9513\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 9s 511ms/step - loss: 0.0285 - accuracy: 0.9481 - val_loss: 0.0646 - val_accuracy: 0.9493\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 9s 555ms/step - loss: 0.0283 - accuracy: 0.9481 - val_loss: 0.0650 - val_accuracy: 0.9507\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 9s 505ms/step - loss: 0.0282 - accuracy: 0.9484 - val_loss: 0.0605 - val_accuracy: 0.9508\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 9s 524ms/step - loss: 0.0277 - accuracy: 0.9487 - val_loss: 0.0520 - val_accuracy: 0.9496\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 8s 467ms/step - loss: 0.0274 - accuracy: 0.9486 - val_loss: 0.0510 - val_accuracy: 0.9476\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 8s 470ms/step - loss: 0.0269 - accuracy: 0.9496 - val_loss: 0.0490 - val_accuracy: 0.9479\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 8s 468ms/step - loss: 0.0264 - accuracy: 0.9497 - val_loss: 0.0441 - val_accuracy: 0.9478\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 0.0260 - accuracy: 0.9499 - val_loss: 0.0447 - val_accuracy: 0.9480\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 8s 456ms/step - loss: 0.0257 - accuracy: 0.9500 - val_loss: 0.0432 - val_accuracy: 0.9482\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 0.0258 - accuracy: 0.9503 - val_loss: 0.0422 - val_accuracy: 0.9477\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 8s 449ms/step - loss: 0.0255 - accuracy: 0.9502 - val_loss: 0.0367 - val_accuracy: 0.9464\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 9s 540ms/step - loss: 0.0253 - accuracy: 0.9505 - val_loss: 0.0374 - val_accuracy: 0.9465\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 10s 560ms/step - loss: 0.0252 - accuracy: 0.9508 - val_loss: 0.0382 - val_accuracy: 0.9479\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 8s 494ms/step - loss: 0.0241 - accuracy: 0.9515 - val_loss: 0.0345 - val_accuracy: 0.9456\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 8s 477ms/step - loss: 0.0241 - accuracy: 0.9513 - val_loss: 0.0346 - val_accuracy: 0.9476\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 8s 488ms/step - loss: 0.0239 - accuracy: 0.9514 - val_loss: 0.0357 - val_accuracy: 0.9475\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 9s 537ms/step - loss: 0.0233 - accuracy: 0.9519 - val_loss: 0.0380 - val_accuracy: 0.9494\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 10s 618ms/step - loss: 0.0233 - accuracy: 0.9519 - val_loss: 0.0363 - val_accuracy: 0.9482\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 9s 511ms/step - loss: 0.0232 - accuracy: 0.9521 - val_loss: 0.0367 - val_accuracy: 0.9468\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 8s 498ms/step - loss: 0.0232 - accuracy: 0.9522 - val_loss: 0.0352 - val_accuracy: 0.9475\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 9s 513ms/step - loss: 0.0232 - accuracy: 0.9520 - val_loss: 0.0344 - val_accuracy: 0.9472\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 9s 543ms/step - loss: 0.0228 - accuracy: 0.9524 - val_loss: 0.0340 - val_accuracy: 0.9479\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 0.0228 - accuracy: 0.9524 - val_loss: 0.0346 - val_accuracy: 0.9493\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 9s 518ms/step - loss: 0.0222 - accuracy: 0.9528 - val_loss: 0.0341 - val_accuracy: 0.9467\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 11s 661ms/step - loss: 0.0224 - accuracy: 0.9525 - val_loss: 0.0351 - val_accuracy: 0.9485\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 9s 545ms/step - loss: 0.0224 - accuracy: 0.9528 - val_loss: 0.0358 - val_accuracy: 0.9482\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 8s 502ms/step - loss: 0.0219 - accuracy: 0.9530 - val_loss: 0.0340 - val_accuracy: 0.9483\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 10s 580ms/step - loss: 0.0214 - accuracy: 0.9536 - val_loss: 0.0360 - val_accuracy: 0.9480\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 10s 574ms/step - loss: 0.0213 - accuracy: 0.9535 - val_loss: 0.0366 - val_accuracy: 0.9484\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 9s 512ms/step - loss: 0.0217 - accuracy: 0.9533 - val_loss: 0.0385 - val_accuracy: 0.9473\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 9s 504ms/step - loss: 0.0212 - accuracy: 0.9536 - val_loss: 0.0350 - val_accuracy: 0.9492\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 8s 502ms/step - loss: 0.0210 - accuracy: 0.9537 - val_loss: 0.0381 - val_accuracy: 0.9496\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 8s 484ms/step - loss: 0.0209 - accuracy: 0.9538 - val_loss: 0.0391 - val_accuracy: 0.9503\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 8s 483ms/step - loss: 0.0212 - accuracy: 0.9535 - val_loss: 0.0389 - val_accuracy: 0.9496\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 8s 489ms/step - loss: 0.0205 - accuracy: 0.9540 - val_loss: 0.0362 - val_accuracy: 0.9486\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 8s 479ms/step - loss: 0.0202 - accuracy: 0.9544 - val_loss: 0.0345 - val_accuracy: 0.9498\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 9s 540ms/step - loss: 0.0202 - accuracy: 0.9543 - val_loss: 0.0346 - val_accuracy: 0.9497\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 8s 486ms/step - loss: 0.0198 - accuracy: 0.9547 - val_loss: 0.0374 - val_accuracy: 0.9484\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 8s 501ms/step - loss: 0.0204 - accuracy: 0.9542 - val_loss: 0.0399 - val_accuracy: 0.9492\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 8s 472ms/step - loss: 0.0201 - accuracy: 0.9545 - val_loss: 0.0359 - val_accuracy: 0.9487\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 9s 504ms/step - loss: 0.0196 - accuracy: 0.9549 - val_loss: 0.0361 - val_accuracy: 0.9489\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 9s 558ms/step - loss: 0.0193 - accuracy: 0.9551 - val_loss: 0.0355 - val_accuracy: 0.9490\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 9s 504ms/step - loss: 0.0194 - accuracy: 0.9549 - val_loss: 0.0367 - val_accuracy: 0.9484\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 8s 476ms/step - loss: 0.0195 - accuracy: 0.9551 - val_loss: 0.0355 - val_accuracy: 0.9476\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 8s 497ms/step - loss: 0.0193 - accuracy: 0.9549 - val_loss: 0.0363 - val_accuracy: 0.9485\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 8s 473ms/step - loss: 0.0192 - accuracy: 0.9551 - val_loss: 0.0393 - val_accuracy: 0.9488\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 7s 430ms/step - loss: 0.0190 - accuracy: 0.9553 - val_loss: 0.0373 - val_accuracy: 0.9481\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 7s 427ms/step - loss: 0.0190 - accuracy: 0.9552 - val_loss: 0.0374 - val_accuracy: 0.9485\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 7s 422ms/step - loss: 0.0190 - accuracy: 0.9552 - val_loss: 0.0370 - val_accuracy: 0.9468\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 7s 434ms/step - loss: 0.0190 - accuracy: 0.9553 - val_loss: 0.0403 - val_accuracy: 0.9479\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 8s 475ms/step - loss: 0.0188 - accuracy: 0.9554 - val_loss: 0.0387 - val_accuracy: 0.9490\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 7s 439ms/step - loss: 0.0187 - accuracy: 0.9556 - val_loss: 0.0388 - val_accuracy: 0.9482\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 7s 426ms/step - loss: 0.0181 - accuracy: 0.9559 - val_loss: 0.0362 - val_accuracy: 0.9484\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 7s 434ms/step - loss: 0.0179 - accuracy: 0.9560 - val_loss: 0.0365 - val_accuracy: 0.9483\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 8s 469ms/step - loss: 0.0183 - accuracy: 0.9558 - val_loss: 0.0393 - val_accuracy: 0.9479\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 9s 514ms/step - loss: 0.0187 - accuracy: 0.9555 - val_loss: 0.0358 - val_accuracy: 0.9491\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 0.0186 - accuracy: 0.9557 - val_loss: 0.0355 - val_accuracy: 0.9474\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 8s 496ms/step - loss: 0.0184 - accuracy: 0.9556 - val_loss: 0.0381 - val_accuracy: 0.9477\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 9s 565ms/step - loss: 0.0187 - accuracy: 0.9555 - val_loss: 0.0412 - val_accuracy: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db34862440>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=init_lr)\n",
    "model_unet.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = 'accuracy')\n",
    "model_unet.fit(x = fieldMNIST_train, y = targetMNIST_train, validation_data=(fieldMNIST_val, targetMNIST_val), batch_size = 20, epochs = total_epoch, \n",
    "               callbacks = [EarlyStopping(monitor='loss',patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "416/416 [==============================] - 18s 36ms/step - loss: 0.4786 - accuracy: 0.1752 - lr: 1.0000e-06\n",
      "Epoch 2/200\n",
      "416/416 [==============================] - 19s 45ms/step - loss: 0.4557 - accuracy: 0.2068 - lr: 9.7712e-07\n",
      "Epoch 3/200\n",
      "416/416 [==============================] - 18s 44ms/step - loss: 0.4305 - accuracy: 0.2456 - lr: 9.5477e-07\n",
      "Epoch 4/200\n",
      "416/416 [==============================] - 20s 48ms/step - loss: 0.4059 - accuracy: 0.2870 - lr: 9.3293e-07\n",
      "Epoch 5/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.3819 - accuracy: 0.3316 - lr: 9.1159e-07\n",
      "Epoch 6/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.3586 - accuracy: 0.3787 - lr: 8.9074e-07\n",
      "Epoch 7/200\n",
      "416/416 [==============================] - 16s 38ms/step - loss: 0.3360 - accuracy: 0.4283 - lr: 8.7036e-07\n",
      "Epoch 8/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.3142 - accuracy: 0.4801 - lr: 8.5045e-07\n",
      "Epoch 9/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.2936 - accuracy: 0.5325 - lr: 8.3099e-07\n",
      "Epoch 10/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.2743 - accuracy: 0.5822 - lr: 8.1198e-07\n",
      "Epoch 11/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.2564 - accuracy: 0.6294 - lr: 7.9341e-07\n",
      "Epoch 12/200\n",
      "416/416 [==============================] - 19s 45ms/step - loss: 0.2401 - accuracy: 0.6726 - lr: 7.7526e-07\n",
      "Epoch 13/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.2254 - accuracy: 0.7117 - lr: 7.5753e-07\n",
      "Epoch 14/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.2122 - accuracy: 0.7465 - lr: 7.4020e-07\n",
      "Epoch 15/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.2004 - accuracy: 0.7762 - lr: 7.2326e-07\n",
      "Epoch 16/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.1901 - accuracy: 0.8020 - lr: 7.0672e-07\n",
      "Epoch 17/200\n",
      "416/416 [==============================] - 19s 45ms/step - loss: 0.1809 - accuracy: 0.8245 - lr: 6.9055e-07\n",
      "Epoch 18/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1728 - accuracy: 0.8432 - lr: 6.7475e-07\n",
      "Epoch 19/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.1657 - accuracy: 0.8585 - lr: 6.5932e-07\n",
      "Epoch 20/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1594 - accuracy: 0.8714 - lr: 6.4424e-07\n",
      "Epoch 21/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1538 - accuracy: 0.8818 - lr: 6.2950e-07\n",
      "Epoch 22/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.1489 - accuracy: 0.8916 - lr: 6.1510e-07\n",
      "Epoch 23/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1444 - accuracy: 0.8986 - lr: 6.0103e-07\n",
      "Epoch 24/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.1404 - accuracy: 0.9046 - lr: 5.8728e-07\n",
      "Epoch 25/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1368 - accuracy: 0.9097 - lr: 5.7384e-07\n",
      "Epoch 26/200\n",
      "416/416 [==============================] - 19s 46ms/step - loss: 0.1336 - accuracy: 0.9142 - lr: 5.6072e-07\n",
      "Epoch 27/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.1306 - accuracy: 0.9182 - lr: 5.4789e-07\n",
      "Epoch 28/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.1280 - accuracy: 0.9213 - lr: 5.3536e-07\n",
      "Epoch 29/200\n",
      "416/416 [==============================] - 19s 45ms/step - loss: 0.1255 - accuracy: 0.9245 - lr: 5.2311e-07\n",
      "Epoch 30/200\n",
      "416/416 [==============================] - 18s 42ms/step - loss: 0.1232 - accuracy: 0.9262 - lr: 5.1114e-07\n",
      "Epoch 31/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.1211 - accuracy: 0.9284 - lr: 4.9945e-07\n",
      "Epoch 32/200\n",
      "416/416 [==============================] - 16s 38ms/step - loss: 0.1192 - accuracy: 0.9308 - lr: 4.8803e-07\n",
      "Epoch 33/200\n",
      "416/416 [==============================] - 16s 38ms/step - loss: 0.1174 - accuracy: 0.9316 - lr: 4.7686e-07\n",
      "Epoch 34/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.1157 - accuracy: 0.9329 - lr: 4.6595e-07\n",
      "Epoch 35/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.1142 - accuracy: 0.9346 - lr: 4.5529e-07\n",
      "Epoch 36/200\n",
      "416/416 [==============================] - 16s 38ms/step - loss: 0.1127 - accuracy: 0.9351 - lr: 4.4488e-07\n",
      "Epoch 37/200\n",
      "416/416 [==============================] - 16s 38ms/step - loss: 0.1113 - accuracy: 0.9363 - lr: 4.3470e-07\n",
      "Epoch 38/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1100 - accuracy: 0.9365 - lr: 4.2476e-07\n",
      "Epoch 39/200\n",
      "416/416 [==============================] - 16s 40ms/step - loss: 0.1088 - accuracy: 0.9372 - lr: 4.1504e-07\n",
      "Epoch 40/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.1076 - accuracy: 0.9379 - lr: 4.0555e-07\n",
      "Epoch 41/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.1065 - accuracy: 0.9385 - lr: 3.9627e-07\n",
      "Epoch 42/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1055 - accuracy: 0.9389 - lr: 3.8720e-07\n",
      "Epoch 43/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.1045 - accuracy: 0.9392 - lr: 3.7835e-07\n",
      "Epoch 44/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.1036 - accuracy: 0.9396 - lr: 3.6969e-07\n",
      "Epoch 45/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.1027 - accuracy: 0.9401 - lr: 3.6123e-07\n",
      "Epoch 46/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1018 - accuracy: 0.9401 - lr: 3.5297e-07\n",
      "Epoch 47/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.1010 - accuracy: 0.9405 - lr: 3.4490e-07\n",
      "Epoch 48/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.1002 - accuracy: 0.9409 - lr: 3.3701e-07\n",
      "Epoch 49/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.0994 - accuracy: 0.9409 - lr: 3.2930e-07\n",
      "Epoch 50/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.0987 - accuracy: 0.9413 - lr: 3.2176e-07\n",
      "Epoch 51/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.0980 - accuracy: 0.9414 - lr: 3.1440e-07\n",
      "Epoch 52/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.0973 - accuracy: 0.9413 - lr: 3.0721e-07\n",
      "Epoch 53/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.0967 - accuracy: 0.9416 - lr: 3.0018e-07\n",
      "Epoch 54/200\n",
      "416/416 [==============================] - 16s 39ms/step - loss: 0.0961 - accuracy: 0.9417 - lr: 2.9332e-07\n",
      "Epoch 55/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0955 - accuracy: 0.9418 - lr: 2.8661e-07\n",
      "Epoch 56/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.0949 - accuracy: 0.9418 - lr: 2.8005e-07\n",
      "Epoch 57/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.0944 - accuracy: 0.9420 - lr: 2.7364e-07\n",
      "Epoch 58/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.0938 - accuracy: 0.9419 - lr: 2.6738e-07\n",
      "Epoch 59/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0933 - accuracy: 0.9421 - lr: 2.6127e-07\n",
      "Epoch 60/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.0928 - accuracy: 0.9421 - lr: 2.5529e-07\n",
      "Epoch 61/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0923 - accuracy: 0.9419 - lr: 2.4945e-07\n",
      "Epoch 62/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0919 - accuracy: 0.9421 - lr: 2.4374e-07\n",
      "Epoch 63/200\n",
      "416/416 [==============================] - 18s 42ms/step - loss: 0.0914 - accuracy: 0.9422 - lr: 2.3817e-07\n",
      "Epoch 64/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0910 - accuracy: 0.9423 - lr: 2.3272e-07\n",
      "Epoch 65/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0906 - accuracy: 0.9421 - lr: 2.2740e-07\n",
      "Epoch 66/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.0902 - accuracy: 0.9422 - lr: 2.2219e-07\n",
      "Epoch 67/200\n",
      "416/416 [==============================] - 17s 40ms/step - loss: 0.0898 - accuracy: 0.9422 - lr: 2.1711e-07\n",
      "Epoch 68/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0894 - accuracy: 0.9422 - lr: 2.1215e-07\n",
      "Epoch 69/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0890 - accuracy: 0.9423 - lr: 2.0729e-07\n",
      "Epoch 70/200\n",
      "416/416 [==============================] - 18s 42ms/step - loss: 0.0887 - accuracy: 0.9423 - lr: 2.0255e-07\n",
      "Epoch 71/200\n",
      "416/416 [==============================] - 17s 41ms/step - loss: 0.0884 - accuracy: 0.9423 - lr: 1.9792e-07\n",
      "Epoch 72/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.0880 - accuracy: 0.9423 - lr: 1.9339e-07\n",
      "Epoch 73/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.0877 - accuracy: 0.9424 - lr: 1.8897e-07\n",
      "Epoch 74/200\n",
      "416/416 [==============================] - 19s 46ms/step - loss: 0.0874 - accuracy: 0.9422 - lr: 1.8464e-07\n",
      "Epoch 75/200\n",
      "416/416 [==============================] - 17s 42ms/step - loss: 0.0871 - accuracy: 0.9423 - lr: 1.8042e-07\n",
      "Epoch 76/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0868 - accuracy: 0.9421 - lr: 1.7629e-07\n",
      "Epoch 77/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0865 - accuracy: 0.9422 - lr: 1.7226e-07\n",
      "Epoch 78/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0863 - accuracy: 0.9422 - lr: 1.6832e-07\n",
      "Epoch 79/200\n",
      "416/416 [==============================] - 20s 48ms/step - loss: 0.0860 - accuracy: 0.9422 - lr: 1.6447e-07\n",
      "Epoch 80/200\n",
      "416/416 [==============================] - 23s 54ms/step - loss: 0.0857 - accuracy: 0.9422 - lr: 1.6071e-07\n",
      "Epoch 81/200\n",
      "416/416 [==============================] - 25s 61ms/step - loss: 0.0855 - accuracy: 0.9422 - lr: 1.5703e-07\n",
      "Epoch 82/200\n",
      "416/416 [==============================] - 22s 53ms/step - loss: 0.0853 - accuracy: 0.9422 - lr: 1.5344e-07\n",
      "Epoch 83/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0850 - accuracy: 0.9421 - lr: 1.4993e-07\n",
      "Epoch 84/200\n",
      "416/416 [==============================] - 18s 44ms/step - loss: 0.0848 - accuracy: 0.9421 - lr: 1.4650e-07\n",
      "Epoch 85/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0846 - accuracy: 0.9421 - lr: 1.4315e-07\n",
      "Epoch 86/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0844 - accuracy: 0.9421 - lr: 1.3987e-07\n",
      "Epoch 87/200\n",
      "416/416 [==============================] - 19s 45ms/step - loss: 0.0842 - accuracy: 0.9420 - lr: 1.3667e-07\n",
      "Epoch 88/200\n",
      "416/416 [==============================] - 18s 44ms/step - loss: 0.0840 - accuracy: 0.9421 - lr: 1.3355e-07\n",
      "Epoch 89/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0838 - accuracy: 0.9421 - lr: 1.3049e-07\n",
      "Epoch 90/200\n",
      "416/416 [==============================] - 18s 42ms/step - loss: 0.0836 - accuracy: 0.9421 - lr: 1.2751e-07\n",
      "Epoch 91/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0834 - accuracy: 0.9420 - lr: 1.2459e-07\n",
      "Epoch 92/200\n",
      "416/416 [==============================] - 18s 44ms/step - loss: 0.0832 - accuracy: 0.9420 - lr: 1.2174e-07\n",
      "Epoch 93/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0831 - accuracy: 0.9419 - lr: 1.1895e-07\n",
      "Epoch 94/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0829 - accuracy: 0.9420 - lr: 1.1623e-07\n",
      "Epoch 95/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0827 - accuracy: 0.9420 - lr: 1.1357e-07\n",
      "Epoch 96/200\n",
      "416/416 [==============================] - 18s 42ms/step - loss: 0.0826 - accuracy: 0.9419 - lr: 1.1098e-07\n",
      "Epoch 97/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0824 - accuracy: 0.9420 - lr: 1.0844e-07\n",
      "Epoch 98/200\n",
      "416/416 [==============================] - 18s 42ms/step - loss: 0.0823 - accuracy: 0.9419 - lr: 1.0596e-07\n",
      "Epoch 99/200\n",
      "416/416 [==============================] - 20s 47ms/step - loss: 0.0822 - accuracy: 0.9419 - lr: 1.0353e-07\n",
      "Epoch 100/200\n",
      "416/416 [==============================] - 19s 45ms/step - loss: 0.0820 - accuracy: 0.9419 - lr: 1.0116e-07\n",
      "Epoch 101/200\n",
      "416/416 [==============================] - 23s 56ms/step - loss: 0.0819 - accuracy: 0.9419 - lr: 9.8850e-08\n",
      "Epoch 102/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0818 - accuracy: 0.9419 - lr: 9.6588e-08\n",
      "Epoch 103/200\n",
      "416/416 [==============================] - 26s 62ms/step - loss: 0.0816 - accuracy: 0.9419 - lr: 9.4379e-08\n",
      "Epoch 104/200\n",
      "416/416 [==============================] - 26s 61ms/step - loss: 0.0815 - accuracy: 0.9418 - lr: 9.2220e-08\n",
      "Epoch 105/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0814 - accuracy: 0.9419 - lr: 9.0110e-08\n",
      "Epoch 106/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0813 - accuracy: 0.9418 - lr: 8.8049e-08\n",
      "Epoch 107/200\n",
      "416/416 [==============================] - 26s 63ms/step - loss: 0.0812 - accuracy: 0.9418 - lr: 8.6035e-08\n",
      "Epoch 108/200\n",
      "416/416 [==============================] - 26s 63ms/step - loss: 0.0811 - accuracy: 0.9418 - lr: 8.4067e-08\n",
      "Epoch 109/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0810 - accuracy: 0.9418 - lr: 8.2143e-08\n",
      "Epoch 110/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0809 - accuracy: 0.9418 - lr: 8.0264e-08\n",
      "Epoch 111/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0808 - accuracy: 0.9418 - lr: 7.8428e-08\n",
      "Epoch 112/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0807 - accuracy: 0.9418 - lr: 7.6634e-08\n",
      "Epoch 113/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0806 - accuracy: 0.9418 - lr: 7.4881e-08\n",
      "Epoch 114/200\n",
      "416/416 [==============================] - 26s 61ms/step - loss: 0.0805 - accuracy: 0.9418 - lr: 7.3168e-08\n",
      "Epoch 115/200\n",
      "416/416 [==============================] - 26s 61ms/step - loss: 0.0804 - accuracy: 0.9418 - lr: 7.1494e-08\n",
      "Epoch 116/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0803 - accuracy: 0.9418 - lr: 6.9859e-08\n",
      "Epoch 117/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0803 - accuracy: 0.9417 - lr: 6.8261e-08\n",
      "Epoch 118/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0802 - accuracy: 0.9418 - lr: 6.6699e-08\n",
      "Epoch 119/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0801 - accuracy: 0.9417 - lr: 6.5173e-08\n",
      "Epoch 120/200\n",
      "416/416 [==============================] - 27s 64ms/step - loss: 0.0800 - accuracy: 0.9417 - lr: 6.3682e-08\n",
      "Epoch 121/200\n",
      "416/416 [==============================] - 25s 61ms/step - loss: 0.0800 - accuracy: 0.9418 - lr: 6.2226e-08\n",
      "Epoch 122/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0799 - accuracy: 0.9417 - lr: 6.0802e-08\n",
      "Epoch 123/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0798 - accuracy: 0.9417 - lr: 5.9411e-08\n",
      "Epoch 124/200\n",
      "416/416 [==============================] - 26s 61ms/step - loss: 0.0798 - accuracy: 0.9417 - lr: 5.8052e-08\n",
      "Epoch 125/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0797 - accuracy: 0.9417 - lr: 5.6724e-08\n",
      "Epoch 126/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0797 - accuracy: 0.9417 - lr: 5.5427e-08\n",
      "Epoch 127/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0796 - accuracy: 0.9417 - lr: 5.4159e-08\n",
      "Epoch 128/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0795 - accuracy: 0.9417 - lr: 5.2920e-08\n",
      "Epoch 129/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0795 - accuracy: 0.9417 - lr: 5.1709e-08\n",
      "Epoch 130/200\n",
      "416/416 [==============================] - 24s 57ms/step - loss: 0.0794 - accuracy: 0.9417 - lr: 5.0526e-08\n",
      "Epoch 131/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0794 - accuracy: 0.9417 - lr: 4.9370e-08\n",
      "Epoch 132/200\n",
      "416/416 [==============================] - 26s 63ms/step - loss: 0.0793 - accuracy: 0.9417 - lr: 4.8241e-08\n",
      "Epoch 133/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0793 - accuracy: 0.9417 - lr: 4.7138e-08\n",
      "Epoch 134/200\n",
      "416/416 [==============================] - 26s 63ms/step - loss: 0.0792 - accuracy: 0.9417 - lr: 4.6059e-08\n",
      "Epoch 135/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0792 - accuracy: 0.9417 - lr: 4.5006e-08\n",
      "Epoch 136/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0792 - accuracy: 0.9417 - lr: 4.3976e-08\n",
      "Epoch 137/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0791 - accuracy: 0.9417 - lr: 4.2970e-08\n",
      "Epoch 138/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0791 - accuracy: 0.9417 - lr: 4.1987e-08\n",
      "Epoch 139/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0790 - accuracy: 0.9417 - lr: 4.1027e-08\n",
      "Epoch 140/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0790 - accuracy: 0.9417 - lr: 4.0088e-08\n",
      "Epoch 141/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0790 - accuracy: 0.9417 - lr: 3.9171e-08\n",
      "Epoch 142/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0789 - accuracy: 0.9417 - lr: 3.8275e-08\n",
      "Epoch 143/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0789 - accuracy: 0.9417 - lr: 3.7399e-08\n",
      "Epoch 144/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0789 - accuracy: 0.9417 - lr: 3.6544e-08\n",
      "Epoch 145/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0788 - accuracy: 0.9417 - lr: 3.5708e-08\n",
      "Epoch 146/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0788 - accuracy: 0.9417 - lr: 3.4891e-08\n",
      "Epoch 147/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0788 - accuracy: 0.9417 - lr: 3.4093e-08\n",
      "Epoch 148/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0788 - accuracy: 0.9417 - lr: 3.3313e-08\n",
      "Epoch 149/200\n",
      "416/416 [==============================] - 24s 57ms/step - loss: 0.0787 - accuracy: 0.9417 - lr: 3.2551e-08\n",
      "Epoch 150/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0787 - accuracy: 0.9417 - lr: 3.1806e-08\n",
      "Epoch 151/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0787 - accuracy: 0.9417 - lr: 3.1079e-08\n",
      "Epoch 152/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0786 - accuracy: 0.9417 - lr: 3.0368e-08\n",
      "Epoch 153/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0786 - accuracy: 0.9417 - lr: 2.9673e-08\n",
      "Epoch 154/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0786 - accuracy: 0.9417 - lr: 2.8994e-08\n",
      "Epoch 155/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0786 - accuracy: 0.9417 - lr: 2.8331e-08\n",
      "Epoch 156/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0786 - accuracy: 0.9417 - lr: 2.7683e-08\n",
      "Epoch 157/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0785 - accuracy: 0.9417 - lr: 2.7050e-08\n",
      "Epoch 158/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0785 - accuracy: 0.9417 - lr: 2.6431e-08\n",
      "Epoch 159/200\n",
      "416/416 [==============================] - 25s 61ms/step - loss: 0.0785 - accuracy: 0.9417 - lr: 2.5826e-08\n",
      "Epoch 160/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0785 - accuracy: 0.9417 - lr: 2.5235e-08\n",
      "Epoch 161/200\n",
      "416/416 [==============================] - 26s 62ms/step - loss: 0.0785 - accuracy: 0.9417 - lr: 2.4658e-08\n",
      "Epoch 162/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0784 - accuracy: 0.9417 - lr: 2.4094e-08\n",
      "Epoch 163/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0784 - accuracy: 0.9417 - lr: 2.3543e-08\n",
      "Epoch 164/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0784 - accuracy: 0.9417 - lr: 2.3004e-08\n",
      "Epoch 165/200\n",
      "416/416 [==============================] - 25s 61ms/step - loss: 0.0784 - accuracy: 0.9417 - lr: 2.2478e-08\n",
      "Epoch 166/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0784 - accuracy: 0.9417 - lr: 2.1964e-08\n",
      "Epoch 167/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0784 - accuracy: 0.9417 - lr: 2.1461e-08\n",
      "Epoch 168/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0784 - accuracy: 0.9417 - lr: 2.0970e-08\n",
      "Epoch 169/200\n",
      "416/416 [==============================] - 25s 61ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 2.0491e-08\n",
      "Epoch 170/200\n",
      "416/416 [==============================] - 26s 62ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 2.0022e-08\n",
      "Epoch 171/200\n",
      "416/416 [==============================] - 26s 62ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 1.9564e-08\n",
      "Epoch 172/200\n",
      "416/416 [==============================] - 18s 43ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 1.9116e-08\n",
      "Epoch 173/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 1.8679e-08\n",
      "Epoch 174/200\n",
      "416/416 [==============================] - 24s 57ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 1.8252e-08\n",
      "Epoch 175/200\n",
      "416/416 [==============================] - 23s 55ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 1.7834e-08\n",
      "Epoch 176/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 1.7426e-08\n",
      "Epoch 177/200\n",
      "416/416 [==============================] - 25s 61ms/step - loss: 0.0783 - accuracy: 0.9417 - lr: 1.7028e-08\n",
      "Epoch 178/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.6638e-08\n",
      "Epoch 179/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.6258e-08\n",
      "Epoch 180/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.5886e-08\n",
      "Epoch 181/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.5522e-08\n",
      "Epoch 182/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.5167e-08\n",
      "Epoch 183/200\n",
      "416/416 [==============================] - 24s 57ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.4820e-08\n",
      "Epoch 184/200\n",
      "416/416 [==============================] - 21s 50ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.4481e-08\n",
      "Epoch 185/200\n",
      "416/416 [==============================] - 19s 47ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.4150e-08\n",
      "Epoch 186/200\n",
      "416/416 [==============================] - 23s 56ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.3826e-08\n",
      "Epoch 187/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.3510e-08\n",
      "Epoch 188/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.3201e-08\n",
      "Epoch 189/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.2899e-08\n",
      "Epoch 190/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0782 - accuracy: 0.9417 - lr: 1.2604e-08\n",
      "Epoch 191/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.2316e-08\n",
      "Epoch 192/200\n",
      "416/416 [==============================] - 24s 59ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.2034e-08\n",
      "Epoch 193/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.1758e-08\n",
      "Epoch 194/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.1490e-08\n",
      "Epoch 195/200\n",
      "416/416 [==============================] - 25s 59ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.1227e-08\n",
      "Epoch 196/200\n",
      "416/416 [==============================] - 25s 60ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.0970e-08\n",
      "Epoch 197/200\n",
      "416/416 [==============================] - 24s 57ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.0719e-08\n",
      "Epoch 198/200\n",
      "416/416 [==============================] - 29s 70ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.0474e-08\n",
      "Epoch 199/200\n",
      "416/416 [==============================] - 26s 63ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.0234e-08\n",
      "Epoch 200/200\n",
      "416/416 [==============================] - 24s 58ms/step - loss: 0.0781 - accuracy: 0.9417 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "# sgd_opt_model = SGD_opt(model_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 113ms/step\n"
     ]
    }
   ],
   "source": [
    "pred1 = model_unet.predict(fieldMNIST_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1728x1728 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(24, 24))\n",
    "\n",
    "axs[0].matshow(fieldMNIST_test[1])\n",
    "axs[1].matshow(targetMNIST_test[1])\n",
    "axs[2].matshow(pred1[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1728x1728 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(24, 24))\n",
    "\n",
    "axs[0].matshow(fieldMNIST_test[2])\n",
    "axs[1].matshow(targetMNIST_test[2])\n",
    "axs[2].matshow(pred1[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1728x1728 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(24, 24))\n",
    "\n",
    "axs[0].matshow(fieldMNIST_test[3])\n",
    "axs[1].matshow(targetMNIST_test[3])\n",
    "axs[2].matshow(pred1[3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "pred2 = model_unet.predict(field_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1728x1728 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(24, 24))\n",
    "\n",
    "axs[0].matshow(field_test[1])\n",
    "axs[1].matshow(target_test[1])\n",
    "axs[2].matshow(pred2[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=init_lr)\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = 'accuracy')\n",
    "model.fit(x = fieldMNIST_train, y = targetMNIST_train, batch_size = 20, epochs = total_epoch, callbacks = [LearningRateScheduler(lr_scheduler)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 8s 267ms/step - loss: 0.1009 - accuracy: 0.9455 - lr: 1.0000e-06\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 6s 267ms/step - loss: 0.0982 - accuracy: 0.9459 - lr: 9.7712e-07\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 6s 277ms/step - loss: 0.0970 - accuracy: 0.9459 - lr: 9.5477e-07\n",
      "Epoch 4/200\n",
      " 3/21 [===>..........................] - ETA: 4s - loss: 0.0934 - accuracy: 0.9500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m adam_opt_model \u001b[38;5;241m=\u001b[39m \u001b[43mAdam_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_unet\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36mAdam_opt\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39minit_lr)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfieldMNIST_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargetMNIST_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adam_opt_model = Adam_opt(model_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
